{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jhonr\\anaconda3\\envs\\ods_unificado\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jhonr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para procesamiento de texto\n",
    "import re\n",
    "import string\n",
    "import langdetect\n",
    "from langdetect import detect, DetectorFactory\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Extracción de palabras clave\n",
    "import yake\n",
    "from yake import KeywordExtractor\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# Similitud semántica\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Visualización y análisis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Modelado y evaluación\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Utilidades\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo en uso: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==================== Configuración de semilla y dispositivo ====================\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo en uso: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_yake(texto):\n",
    "    if not texto or texto.strip() == '':\n",
    "        return 'Texto vacío'\n",
    "    texto = BeautifulSoup(texto, \"html.parser\").get_text()\n",
    "    texto = texto.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    texto = re.sub(r'\\b(introduction|methods|results|discussion|conclusion)\\b', '', texto, flags=re.IGNORECASE)\n",
    "    texto = re.sub(r'[^\\w\\s.,]', '', texto)  # conserva solo letras, números, espacios y puntuación mínima\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Preprocesamiento para BERT ====================\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def contiene_ingles(texto):\n",
    "    try:\n",
    "        palabras = texto.lower().split()\n",
    "        palabras_ingles = set([\"the\", \"is\", \"are\", \"this\", \"with\", \"and\", \"from\", \"to\", \"of\", \"that\"])\n",
    "        return any(p in palabras for p in palabras_ingles)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def limpiar_bert(texto):\n",
    "    if not texto or texto.strip() == '':\n",
    "        return 'Texto vacío'\n",
    "\n",
    "    texto_limpio = BeautifulSoup(texto, \"html.parser\").get_text()\n",
    "    texto_limpio = texto_limpio.lower()\n",
    "\n",
    "    texto_limpio = re.sub(\n",
    "        r'\\b(introduction|aims|objectives|methods|results|discussion|conclusion|background|purpose|scope)\\b[:\\s]*',\n",
    "        '', texto_limpio, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    texto_limpio = re.sub(\n",
    "        r'\\b(this study (aims|explores|presents)|we (present|explore|investigate)|the purpose of this (study|paper))\\b',\n",
    "        '', texto_limpio\n",
    "    )\n",
    "\n",
    "    texto_limpio = re.sub(r'[^a-z0-9\\s.,-]', '', texto_limpio)\n",
    "    texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()\n",
    "    return texto_limpio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Cargar dataset ====================\n",
    "file_path = r\"C:\\Users\\Jhonr\\Project_ODS_BERT\\Data_total\\Data_Inferencia_2018_2024_medicina_ingenieria.xlsx\"\n",
    "df_total = pd.read_excel(file_path)\n",
    "df_total['Abstract_YAKE'] = df_total['Abstract'].apply(limpiar_yake)\n",
    "df_total['Abstract_BERT'] = df_total['Abstract'].apply(lambda x: limpiar_bert(x) if contiene_ingles(x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Inferencia YAKE ====================\n",
    "from yake import KeywordExtractor\n",
    "\n",
    "# Configurar dos extractores YAKE: unigrama y bigrama\n",
    "extractor_n1 = KeywordExtractor(lan=\"en\", n=1, top=10)\n",
    "extractor_n2 = KeywordExtractor(lan=\"en\", n=2, top=10)\n",
    "\n",
    "ods_keywords = {\n",
    "    \"ODS 6\": [\n",
    "        \"clean water\", \"drinking water\", \"water sanitation\", \"water access\",\n",
    "        \"safe water\", \"water purification\", \"wastewater treatment\", \"sanitation services\",\n",
    "        \"hygiene promotion\", \"water supply\", \"water scarcity\", \"potable water\",\n",
    "        \"water\", \"sanitation\", \"hygiene\", \"wastewater\"\n",
    "    ],\n",
    "    \"ODS 7\": [\n",
    "        \"renewable energy\", \"solar energy\", \"wind power\", \"energy efficiency\",\n",
    "        \"electricity access\", \"clean energy\", \"energy grid\", \"sustainable energy\",\n",
    "        \"off-grid systems\", \"green energy\", \"solar panels\", \"smart grid\",\n",
    "        \"energy\", \"electricity\", \"solar\", \"wind\"\n",
    "    ],\n",
    "    \"ODS 13\": [\n",
    "        \"climate change\", \"global warming\", \"carbon emissions\", \"climate adaptation\",\n",
    "        \"emission reduction\", \"climate resilience\", \"greenhouse gases\",\n",
    "        \"low carbon\", \"carbon footprint\", \"climate mitigation\", \"net zero\",\n",
    "        \"environmental sustainability\", \"climate\", \"carbon\", \"emissions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def clasificar_yake(texto):\n",
    "    if not texto or texto.strip() == '':\n",
    "        return None\n",
    "    keywords_n1 = [kw[0].lower() for kw in extractor_n1.extract_keywords(texto)]\n",
    "    keywords_n2 = [kw[0].lower() for kw in extractor_n2.extract_keywords(texto)]\n",
    "    keywords = keywords_n1 + keywords_n2\n",
    "    for ods, terms in ods_keywords.items():\n",
    "        if any(term in keywords for term in terms):\n",
    "            return ods\n",
    "    return None\n",
    "\n",
    "df_total['prediccion_yake'] = df_total['Abstract_YAKE'].apply(clasificar_yake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Cargar modelos BERT ====================\n",
    "modelo_bert_9_otros_path = r\"C:\\\\Users\\\\Jhonr\\\\Project_ODS_BERT\\\\Modelos\\\\BERT_9_OTROS_UNIFICADO\"\n",
    "modelo_bert_ods3_path = r\"C:\\\\Users\\\\Jhonr\\\\Project_ODS_BERT\\\\Modelos\\\\BERT_ODS3_Medicina\"\n",
    "\n",
    "modelo_bert_9_otros = AutoModelForSequenceClassification.from_pretrained(modelo_bert_9_otros_path).to(device)\n",
    "tokenizer_bert_9_otros = AutoTokenizer.from_pretrained(modelo_bert_9_otros_path)\n",
    "\n",
    "modelo_bert_ods3 = AutoModelForSequenceClassification.from_pretrained(modelo_bert_ods3_path).to(device)\n",
    "tokenizer_bert_ods3 = AutoTokenizer.from_pretrained(modelo_bert_ods3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Función para predecir con modelo BERT ====================\n",
    "def inferir_con_modelo(texto, modelo, tokenizer):\n",
    "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = modelo(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "    return modelo.config.id2label[pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Clasificación final ====================\n",
    "def clasificar_resumen(row):\n",
    "    if row['prediccion_yake'] in [\"ODS 6\", \"ODS 7\", \"ODS 13\"]:\n",
    "        return row['prediccion_yake']\n",
    "    \n",
    "    if row['Abstract_BERT']:\n",
    "        pred_ods3 = inferir_con_modelo(row['Abstract_BERT'], modelo_bert_ods3, tokenizer_bert_ods3)\n",
    "        if pred_ods3 == \"ODS 3\":\n",
    "            return \"ODS 3\"\n",
    "    \n",
    "    if row['Abstract_BERT']:\n",
    "        return inferir_con_modelo(row['Abstract_BERT'], modelo_bert_9_otros, tokenizer_bert_9_otros)\n",
    "    \n",
    "    return \"Sin Clasificar\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de inferencia: 7.07 minutos\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la clasificación sobre el DataFrame\n",
    "import time\n",
    "inicio = time.time()\n",
    "df_total['ODS_Predicho'] = df_total.apply(clasificar_resumen, axis=1)\n",
    "fin = time.time()\n",
    "print(f\"Tiempo total de inferencia: {round((fin - inicio) / 60, 2)} minutos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de etiquetas predichas:\n",
      "ODS_Predicho\n",
      "ODS 3             15905\n",
      "ODS 9              4377\n",
      "OTROS              1692\n",
      "ODS 7               710\n",
      "ODS 6               344\n",
      "ODS 13              197\n",
      "Sin Clasificar        4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Visualizar la distribución final de etiquetas\n",
    "print(\"\\nDistribución de etiquetas predichas:\")\n",
    "print(df_total['ODS_Predicho'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ODS_Predicho</th>\n",
       "      <th>ODS 13</th>\n",
       "      <th>ODS 3</th>\n",
       "      <th>ODS 6</th>\n",
       "      <th>ODS 7</th>\n",
       "      <th>ODS 9</th>\n",
       "      <th>OTROS</th>\n",
       "      <th>Sin Clasificar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ingenieria</th>\n",
       "      <td>153</td>\n",
       "      <td>1101</td>\n",
       "      <td>264</td>\n",
       "      <td>676</td>\n",
       "      <td>4132</td>\n",
       "      <td>1212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medicina</th>\n",
       "      <td>44</td>\n",
       "      <td>14804</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>245</td>\n",
       "      <td>480</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ODS_Predicho  ODS 13  ODS 3  ODS 6  ODS 7  ODS 9  OTROS  Sin Clasificar\n",
       "Area                                                                   \n",
       "Ingenieria       153   1101    264    676   4132   1212               1\n",
       "Medicina          44  14804     80     34    245    480               3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================== Distribución de ODS por Área ====================\n",
    "conteo_area_ods = df_total.groupby([\"Area\", \"ODS_Predicho\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Mostrar la tabla\n",
    "display(conteo_area_ods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en: C:\\Users\\Jhonr\\Project_ODS_BERT\\Resultados_2018-2024\\Predicciones_2018_2024_Modelo_Final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "output_folder = r\"C:\\Users\\Jhonr\\Project_ODS_BERT\\Resultados_2018-2024\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Guardar archivo\n",
    "output_path = os.path.join(output_folder, \"Predicciones_2018_2024_Modelo_Final.xlsx\")\n",
    "df_total.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo guardado en: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ods_unificado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
